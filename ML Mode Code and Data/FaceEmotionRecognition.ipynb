{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb48852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\users\\\\yoyoy\\\\anaconda3\\\\envs\\\\rl\\\\lib\\\\site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a1bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import cv2 \n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d88da41",
   "metadata": {},
   "source": [
    "### Read all images and convert them to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fe599a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datadirectory = \"dataset/train/\"\n",
    "Classes = [\"angry\",\"disgust\",\"fear\",\"happy\",\"neutral\",\"sad\",\"surprise\"]\n",
    "img_size = 224 # ImageNet -> 224 x 224\n",
    "\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in Classes:\n",
    "        path = os.path.join(Datadirectory, category)\n",
    "        class_num = Classes.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                image = cv2.imread(os.path.join(path, img))\n",
    "                #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, (img_size, img_size))\n",
    "                training_data.append([image, class_num])\n",
    "            except Exception as e:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92441f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f3f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd454317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp = np.array(training_data)\n",
    "#temp.shape\n",
    "#temp[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e511772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data) #shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ef47283",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X = np.array(X).reshape(-1, img_size, img_size, 3)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afd3872a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12475, 224, 224, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78aa306a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12475,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Y = np.array(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77b95d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.clear()\n",
    "#Classes.clear()\n",
    "#print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2fa8674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "# you could use scikit-learn\n",
    "\n",
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fca7601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12475, 224, 224, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baf6273",
   "metadata": {},
   "source": [
    "### Deep Learning model for training - Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a40f70f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f169e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.MobileNetV2() #pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1f6d53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb029f",
   "metadata": {},
   "source": [
    "### Transfer Learning - Tuning, weights will start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0190f79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_input = model.layers[0].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "600724a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output = model.layers[-2].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c81a5756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6e5b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = layers.Dense(128)(base_output) #add new layer after global pooling layer\n",
    "final_output = layers.Activation('relu')(final_output) #activation function\n",
    "final_output = layers.Dense(64)(final_output)\n",
    "final_output = layers.Activation('relu')(final_output)\n",
    "final_output = layers.Dense(7, activation='softmax')(final_output) #output is 7 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72624382",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a89692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = keras.Model(inputs = base_input, outputs = final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc7a7f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dcb13bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75702d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "390/390 [==============================] - 1033s 3s/step - loss: 1.4239 - accuracy: 0.4547\n",
      "Epoch 2/30\n",
      "390/390 [==============================] - 974s 2s/step - loss: 1.2228 - accuracy: 0.5343\n",
      "Epoch 3/30\n",
      "390/390 [==============================] - 947s 2s/step - loss: 1.1275 - accuracy: 0.5772\n",
      "Epoch 4/30\n",
      "390/390 [==============================] - 945s 2s/step - loss: 1.0509 - accuracy: 0.6064\n",
      "Epoch 5/30\n",
      "390/390 [==============================] - 889s 2s/step - loss: 0.9898 - accuracy: 0.6305\n",
      "Epoch 6/30\n",
      "390/390 [==============================] - 877s 2s/step - loss: 0.9192 - accuracy: 0.6556\n",
      "Epoch 7/30\n",
      "390/390 [==============================] - 884s 2s/step - loss: 0.8659 - accuracy: 0.6794\n",
      "Epoch 8/30\n",
      "390/390 [==============================] - 887s 2s/step - loss: 0.7984 - accuracy: 0.7024\n",
      "Epoch 9/30\n",
      "390/390 [==============================] - 880s 2s/step - loss: 0.7320 - accuracy: 0.7301\n",
      "Epoch 10/30\n",
      "390/390 [==============================] - 862s 2s/step - loss: 0.6792 - accuracy: 0.7517\n",
      "Epoch 11/30\n",
      "390/390 [==============================] - 879s 2s/step - loss: 0.6109 - accuracy: 0.7744\n",
      "Epoch 12/30\n",
      "390/390 [==============================] - 888s 2s/step - loss: 0.5614 - accuracy: 0.7926\n",
      "Epoch 13/30\n",
      "390/390 [==============================] - 906s 2s/step - loss: 0.5021 - accuracy: 0.8201\n",
      "Epoch 14/30\n",
      "390/390 [==============================] - 901s 2s/step - loss: 0.4462 - accuracy: 0.8382\n",
      "Epoch 15/30\n",
      "390/390 [==============================] - 913s 2s/step - loss: 0.4079 - accuracy: 0.8559\n",
      "Epoch 16/30\n",
      "390/390 [==============================] - 912s 2s/step - loss: 0.3703 - accuracy: 0.8669\n",
      "Epoch 17/30\n",
      "390/390 [==============================] - 876s 2s/step - loss: 0.3218 - accuracy: 0.8869\n",
      "Epoch 18/30\n",
      "390/390 [==============================] - 929s 2s/step - loss: 0.3000 - accuracy: 0.8932\n",
      "Epoch 19/30\n",
      "390/390 [==============================] - 1264s 3s/step - loss: 0.2875 - accuracy: 0.8968\n",
      "Epoch 20/30\n",
      "390/390 [==============================] - 1374s 4s/step - loss: 0.2418 - accuracy: 0.9169\n",
      "Epoch 21/30\n",
      "390/390 [==============================] - 1380s 4s/step - loss: 0.2125 - accuracy: 0.9261\n",
      "Epoch 22/30\n",
      "390/390 [==============================] - 1197s 3s/step - loss: 0.2177 - accuracy: 0.9259\n",
      "Epoch 23/30\n",
      "390/390 [==============================] - 852s 2s/step - loss: 0.1985 - accuracy: 0.9288\n",
      "Epoch 24/30\n",
      "390/390 [==============================] - 848s 2s/step - loss: 0.1816 - accuracy: 0.9377\n",
      "Epoch 25/30\n",
      "390/390 [==============================] - 846s 2s/step - loss: 0.1836 - accuracy: 0.9354\n",
      "Epoch 26/30\n",
      "390/390 [==============================] - 846s 2s/step - loss: 0.1717 - accuracy: 0.9404\n",
      "Epoch 27/30\n",
      "390/390 [==============================] - 844s 2s/step - loss: 0.1482 - accuracy: 0.9493\n",
      "Epoch 28/30\n",
      "390/390 [==============================] - 851s 2s/step - loss: 0.1552 - accuracy: 0.9501\n",
      "Epoch 29/30\n",
      "390/390 [==============================] - 846s 2s/step - loss: 0.1609 - accuracy: 0.9432\n",
      "Epoch 30/30\n",
      "390/390 [==============================] - 847s 2s/step - loss: 0.1348 - accuracy: 0.9550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f18918f580>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(X,y, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8d57e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.save('FER13_Accuracy95.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f08f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
